# ðŸ¤– Flare AI Social

A comprehensive template for building AI-powered social media agents that interact with the Flare Network community through secure model fine-tuning and deployment.

## ðŸ“‹ Overview

TODO

## ðŸ—ï¸ Project Structure

The Flare AI Social template provides a modular architecture for building AI-powered social media agents. Here's a breakdown of the core files and their purposes:

```
src/flare_ai_social/
â”œâ”€â”€ ai/                     # AI Provider implementations
â”‚   â”œâ”€â”€ __init__.py        # Package exports
â”‚   â”œâ”€â”€ base.py            # Base AI provider abstraction
â”‚   â”œâ”€â”€ gemini.py          # Google Gemini integration
â”‚   â””â”€â”€ openrouter.py      # OpenRouter integration
â”œâ”€â”€ attestation/           # TEE attestation implementation
â”‚   â”œâ”€â”€ __init__.py        # Package exports
â”‚   â”œâ”€â”€ simulated_token.txt # Testing token
â”‚   â”œâ”€â”€ vtpm_attestation.py # vTPM client for secure attestation
â”‚   â””â”€â”€ vtpm_validation.py  # Token validation utilities
â”œâ”€â”€ prompts/               # Prompt engineering templates
â”‚   â”œâ”€â”€ __init__.py        # Exports prompt constants
â”‚   â””â”€â”€ templates.py       # Different prompt strategies
â”œâ”€â”€ __init__.py            # Package initialization
â”œâ”€â”€ main.py                # Application entry point
â”œâ”€â”€ settings.py            # Configuration settings
â””â”€â”€ tune_model.py          # Model fine-tuning utilities
```

### Core Scripts and Their Functions

#### `ai/base.py`
Defines the abstraction layer for AI providers with standardized interfaces:
- `BaseAIProvider`: Abstract class that all AI providers must implement
- `ModelResponse`: Standard response format across different AI backends
- `BaseRouter`/`AsyncBaseRouter`: HTTP request handlers for API communication
- Supports both synchronous and asynchronous request patterns

#### `ai/gemini.py`
Google Gemini implementation of the AI provider interface:
- Handles authentication with Google's Generative AI service
- Manages chat history and context
- Supports structured outputs and system instructions
- Implements conversation memory for multi-turn interactions

#### `attestation/vtpm_attestation.py`
TEE-based security implementation:
- `Vtpm` class for interacting with Trusted Execution Environment
- Generates attestation tokens for verifying secure execution
- Supports nonce-based replay protection
- Can operate in simulation mode for testing and development

#### `attestation/vtpm_validation.py`
Verification utilities for attestation tokens:
- Validates certificate chains and signatures
- Supports both PKI and OIDC validation schemes
- Verifies hardware integrity and runtime environment
- Ensures temporal validity of certificates

#### `prompts/templates.py`
Collection of prompt engineering strategies:
- `ZERO_SHOT_PROMPT`: Basic personality definition for the AI agent
- `FEW_SHOT_PROMPT`: Enhanced with examples for better alignment with communication style
- `CHAIN_OF_THOUGHT_PROMPT`: Detailed reasoning framework for complex queries
- Structured reasoning patterns for different query types

#### `settings.py`
Configuration management using Pydantic:
- API credentials for AI providers
- Model tuning parameters (batch size, learning rate, epochs)
- Dataset paths and model identifiers
- Social media platform credentials (X/Twitter API integration)
- Environment variables management with `.env` file support

#### `tune_model.py`
Utilities for fine-tuning models:
- Data loading and validation with minimum dataset size checks
- Model creation, training, and management
- Training visualization and loss metrics analysis
- Performance monitoring with snapshot tracking
- Model deletion and recreation capabilities

#### `main.py`
Application entry point that demonstrates:
- Testing different prompt strategies against standard prompts
- Loading and using tuned models from Google AI studio
- Comparing response quality across different prompting approaches
- Structured logging for result analysis
- Planned functionality for social media integration

### Using the Code

The template provides core functionality for:

1. **Model Tuning**: Fine-tune AI models on custom datasets
   ```python
   # From tune_model.py
   operation = genai.create_tuned_model(
       id=new_model_id,
       source_model=settings.tuning_source_model,
       training_data=training_dataset,
       epoch_count=settings.tuning_epoch_count,
       batch_size=settings.tuning_batch_size,
       learning_rate=settings.tuning_learning_rate,
   )
   
   # Monitor training progress
   for _ in operation.wait_bar():
       pass
       
   # Analyze and visualize results
   snapshots = pd.DataFrame(tuned_model.tuning_task.snapshots)
   plot_path = save_loss_plot(snapshots, new_model_id)
   ```

2. **AI Interaction with Different Prompting Strategies**:
   ```python
   # From main.py - Zero shot prompting
   model_zero_shot = GeminiProvider(
       settings.gemini_api_key,
       model="gemini-1.5-flash",
       system_instruction=ZERO_SHOT_PROMPT,
   )
   
   # Few shot prompting with examples
   model_few_shot = GeminiProvider(
       settings.gemini_api_key,
       model="gemini-1.5-flash",
       system_instruction=FEW_SHOT_PROMPT,
   )
   
   # Chain of thought reasoning
   model_chain_of_thought = GeminiProvider(
       settings.gemini_api_key,
       model="gemini-1.5-flash",
       system_instruction=CHAIN_OF_THOUGHT_PROMPT,
   )
   ```

3. **Response Testing and Analysis**:
   ```python
   # From main.py
   def test_prompts(model: GeminiProvider, label: str) -> None:
       for prompt in TEST_PROMPTS:
           result = model.generate(prompt)
           logger.info(label, prompt=prompt, result=result.text)
   
   # Test with standard prompts
   test_prompts(model=model_zero_shot, label="zero-shot")
   test_prompts(model=model_few_shot, label="few-shot")
   test_prompts(model=model_chain_of_thought, label="chain-of-thought")
   ```

4. **Secure Attestation** (when implementing TEE security):
   ```python
   # Example attestation usage
   from flare_ai_social.attestation import Vtpm, VtpmValidation
   
   # Generate attestation token
   vtpm = Vtpm()
   token = vtpm.get_token(nonces=["random_nonce"])
   
   # Validate token
   validator = VtpmValidation()
   claims = validator.validate_token(token)
   ```